{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling With MongoDB Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project 2 from Udacity Data Analyst Nano Degree program              by Jay Zmudka**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Overview of the data \n",
    "\n",
    "Openstreetmap is an opensource mapping system on the internet that is freely available at http://openstreetmap.com. The data is stored in an XML format. There are several ways to download map data for a given area. I chose to download map data for downtown Detroit, MI because it is near me and I'm familiar with the streets and buildings. I played with the website until I got a file with a size greater than 50MB. The bounds are:\n",
    "    \n",
    "minlat=\"42.3097000\" minlon=\"-83.1011000\" maxlat=\"42.3626000\" maxlon=\"-82.9663000\"\n",
    "\n",
    "I used the overpass-api to download the osm data.\n",
    "https://www.openstreetmap.org/export#map=13/42.3362/-83.0336\n",
    "\n",
    "The data file is around 70 MB and over the recommended maximum size file for Github, so I zipped it to get it down to 6 MB. I also zoomed in further to get a smaller sample.osm file that is 4 mb in size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code below loads the needed libraries for the project and gives a function to open the zip file with the data. To choose the sample or full file, uncomment the one you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from pprint import pprint as pp\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import pymongo\n",
    "\n",
    "samplefile = 'sample.osm'\n",
    "zipfile = 'openstreetmapdata.zip'\n",
    "filename = 'openstreetmapdata'\n",
    "outfile = 'openstreetmapdata.json'\n",
    "\n",
    "# uncomment the data you want to use\n",
    "usefile = samplefile # smaller sample file\n",
    "#usefile = openzipfile(zipfile, filename) #Full size file 70mb\n",
    "\n",
    "# extracts osm file from zip archive\n",
    "def openzipfile(zipf, filename):\n",
    "    with ZipFile(zipf) as osmzip:\n",
    "        xfile = osmzip.open(filename)\n",
    "        return xfile\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems encountered in the map\n",
    "\n",
    "The openstreet data is stuctured in an XML format. It uses 3 map elements.\n",
    "* Node: A point with coordinates and data about that location\n",
    "* Way: Defines linear features like streets and boundaries\n",
    "* Relation: Explains how other elements go together\n",
    "\n",
    "There are also tags with other information with K and V values that are Key:Value pairs.\n",
    "\n",
    "Here is a sample:\n",
    "\n",
    "      <node id=\"5959554765\" visible=\"true\" version=\"3\" changeset=\"63267190\" timestamp=\"2018-10-06T22:00:04Z\" user=\"DougPeterson\" uid=\"1469704\" lat=\"42.3288784\" lon=\"-83.0399180\">\n",
    "      <tag k=\"addr:city\" v=\"Detroit\"/>\n",
    "      <tag k=\"addr:housenumber\" v=\"400\"/>\n",
    "      <tag k=\"addr:postcode\" v=\"48243-1312\"/>\n",
    "      <tag k=\"addr:state\" v=\"MI\"/>\n",
    "      <tag k=\"addr:street\" v=\"Renaissance Drive West\"/>\n",
    "      <tag k=\"name\" v=\"Detroit Marriott at the Renaissance Center\"/>\n",
    "      <tag k=\"operator\" v=\"Marriott\"/>\n",
    "      <tag k=\"phone\" v=\"+1 313-568-8000\"/>\n",
    "      <tag k=\"tourism\" v=\"hotel\"/>\n",
    "      </node>\n",
    "      \n",
    "I wrote some auditing fuctions to find probems with the data\n",
    "I took the following steps:\n",
    "\n",
    "* Checked for abbreviated street names\n",
    "* Checked for invalid URL's\n",
    "* Checked for redundant TIGER data\n",
    "\n",
    "I wrote the following functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auditing functions\n",
    "\n",
    "ROOTTAGS = [ 'node', 'way', 'relation'] #the three map elements\n",
    "\n",
    "# Lists the total tags in .osm file\n",
    "def list_totals(usefile):\n",
    "    tagslist ={}\n",
    "    total = 0\n",
    "    for _, element in ET.iterparse(usefile):\n",
    "        total += 1\n",
    "        if element.tag not in tagslist:\n",
    "            tagslist[element.tag] = 1\n",
    "        else:\n",
    "            tagslist[element.tag] = tagslist[element.tag] + 1\n",
    "    print 'Counting all the tags: \\n'\n",
    "    print total, 'tags in total \\n'\n",
    "    pp(tagslist)\n",
    "\n",
    "# Lists websites with bad URL's    \n",
    "def list_websites(usefile):\n",
    "    websites = []\n",
    "    for _, element in ET.iterparse(usefile):\n",
    "        if len(element.findall('tag')) > 0:\n",
    "            for tag in element.findall('tag'):\n",
    "                if tag.attrib['k'] == 'website':\n",
    "                    websites.append(tag.attrib['v'])\n",
    "    print 'List of websites'\n",
    "    pp(websites)\n",
    "    badurls = []\n",
    "    for w in websites:\n",
    "        if not w.startswith('http'):\n",
    "            badurls.append(w)\n",
    "    print \"\\nThese websites are not proper URL's\" \n",
    "    pp(badurls)\n",
    "    \n",
    "# Lists some ways with redundant tiger tags  \n",
    "def find_tiger(usefile):\n",
    "    tigertags = 0\n",
    "    print 'Samples of ways containing redundant tiger street data:'\n",
    "    for _, element in ET.iterparse(usefile):\n",
    "        if element.tag == 'way':\n",
    "            if len(element.findall('tag')) > 0:\n",
    "                for tag in element.findall('tag'):\n",
    "                    if tag.attrib['k'].startswith('tiger'):\n",
    "                        print ET.tostring(element)\n",
    "                        tigertags += 1\n",
    "                        break           \n",
    "                pass\n",
    "        if tigertags > 1:\n",
    "            break\n",
    "                  \n",
    "#compiles and prints list of street suffixes\n",
    "def street_endings(usefile):\n",
    "    street_endings = set()\n",
    "    for _, element in ET.iterparse(usefile):\n",
    "        if element.tag == 'way':        \n",
    "            if len(element.findall('tag')) > 0:\n",
    "                for tag in element.findall('tag'):\n",
    "                    if tag.attrib['k'] == 'name':\n",
    "                        street_endings.add(tag.attrib['v'].split()[-1])\n",
    "    print street_endings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's audit the data. How many total tags are in the file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting all the tags: \n",
      "\n",
      "74700 tags in total \n",
      "\n",
      "{'bounds': 1,\n",
      " 'member': 45199,\n",
      " 'nd': 10927,\n",
      " 'node': 7577,\n",
      " 'osm': 1,\n",
      " 'relation': 211,\n",
      " 'tag': 9422,\n",
      " 'way': 1362}\n"
     ]
    }
   ],
   "source": [
    "list_totals(usefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class material used street name abbreviations as an example of something to fix. I will make a list of them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Substation', 'Boulevard', 'Group', '600', 'West', 'Pyramid', 'Martius', '#8735', 'Woodward', '300', 'Fountain', 'Authority', 'Lot', 'East', '100', 'Row', 'Suites', 'Parc', 'Deli', 'Amphitheatre', \"Steven's\", 'Park', 'Free', 'Promenade', 'Parking', 'Building)', 'Protection', 'Riverfront', '400', 'Esplanade', 'AT&T', 'Law', 'Hall', 'Bank', 'Rooms', 'Building', '200', 'School', 'Theater', 'Center', 'Tunnel', '(1905)', 'Plaza', 'Drive', 'Detroit', 'Headquarters', 'Freeway', 'Garage', 'Square', 'Place', 'Monument', 'Tower', 'Tavern', 'Patio', '(1928)', 'Apartments', \"DuMouchelle's\", 'House', 'Scientology', 'Deck', 'Alley', 'Qube', 'Street', '500', 'QLINE', 'Church', 'Riverwalk', 'Mover', 'Cafe', 'Avenue', 'Campus', '(1915)'])\n"
     ]
    }
   ],
   "source": [
    "street_endings(usefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't any abbreviations here. That isn't a problem that needs to be fixed in this data set.\n",
    "Here I check for tags with bad website URL's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of websites\n",
      "['http://www.bangkokcrossingthaifood.com/',\n",
      " 'https://www.starbucks.com/store/12550/us/marriott-rencen-detroit/renaissance-center-detroit-mi-48243/renaissance',\n",
      " 'https://citymarketdetroit.com/',\n",
      " 'www.eatdimestore.com',\n",
      " 'https://www.mckinsey.com/midwest/detroit',\n",
      " 'https://entangleagency.com',\n",
      " 'http://cadillacsquarediner.com',\n",
      " 'https://salondetroit.com',\n",
      " 'https://www.newcadillacsquare.com',\n",
      " 'parcderoit.com',\n",
      " 'http://www.sspeterandpauljesuit.org/',\n",
      " 'http://www.christcd.org/',\n",
      " 'http://www.portdetroit.com',\n",
      " 'https://www.bcbsm.com/',\n",
      " 'https://www.tcfcenterdetroit.com/']\n",
      "\n",
      "These websites are not proper URL's\n",
      "['www.eatdimestore.com', 'parcderoit.com']\n"
     ]
    }
   ],
   "source": [
    "list_websites(usefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed some redundant street information in the file. It is from The Topologically Integrated Geographic Encoding and Referencing system (TIGER) data, produced by the US Census Bureau. It was imported into OSM in 2006 and 2007. This is extraneous data because it duplicates the address information already there. Here is how I checked for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples of ways containing redundant tiger street data:\n",
      "<way changeset=\"70380121\" id=\"8732681\" timestamp=\"2019-05-18T07:03:36Z\" uid=\"1240864\" user=\"Howpper\" version=\"20\" visible=\"true\">\n",
      "  <nd ref=\"62601111\" />\n",
      "  <nd ref=\"1254758160\" />\n",
      "  <tag k=\"highway\" v=\"primary\" />\n",
      "  <tag k=\"lanes\" v=\"4\" />\n",
      "  <tag k=\"maxspeed\" v=\"30 mph\" />\n",
      "  <tag k=\"name\" v=\"West Jefferson Avenue\" />\n",
      "  <tag k=\"oneway\" v=\"yes\" />\n",
      "  <tag k=\"ref\" v=\"M 10\" />\n",
      "  <tag k=\"tiger:cfcc\" v=\"A45\" />\n",
      "  <tag k=\"tiger:county\" v=\"Wayne, MI\" />\n",
      "  <tag k=\"tiger:name_base\" v=\"Jefferson\" />\n",
      "  <tag k=\"tiger:name_direction_prefix\" v=\"W\" />\n",
      "  <tag k=\"tiger:name_type\" v=\"Ave\" />\n",
      " </way>\n",
      " \n",
      "<way changeset=\"76521942\" id=\"8734148\" timestamp=\"2019-11-02T08:31:11Z\" uid=\"6656962\" user=\"StudentinGear\" version=\"31\" visible=\"true\">\n",
      "  <nd ref=\"62618538\" />\n",
      "  <nd ref=\"1254758157\" />\n",
      "  <nd ref=\"6938840835\" />\n",
      "  <nd ref=\"5552762753\" />\n",
      "  <nd ref=\"62618540\" />\n",
      "  <nd ref=\"62618542\" />\n",
      "  <nd ref=\"4181389363\" />\n",
      "  <tag k=\"cycleway:right\" v=\"no\" />\n",
      "  <tag k=\"highway\" v=\"primary\" />\n",
      "  <tag k=\"lanes\" v=\"4\" />\n",
      "  <tag k=\"maxspeed\" v=\"30 mph\" />\n",
      "  <tag k=\"name\" v=\"East Jefferson Avenue\" />\n",
      "  <tag k=\"oneway\" v=\"yes\" />\n",
      "  <tag k=\"ref\" v=\"M 10\" />\n",
      "  <tag k=\"tiger:cfcc\" v=\"A41\" />\n",
      "  <tag k=\"tiger:county\" v=\"Wayne, MI\" />\n",
      "  <tag k=\"tiger:name_base\" v=\"Jefferson\" />\n",
      "  <tag k=\"tiger:name_direction_prefix\" v=\"E\" />\n",
      "  <tag k=\"tiger:name_type\" v=\"Ave\" />\n",
      " </way>\n",
      " \n"
     ]
    }
   ],
   "source": [
    "find_tiger(usefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data\n",
    "\n",
    "Here are a couple functions I wrote. One fixes bad URL's and the other removes the tiger tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning functions\n",
    "\n",
    "#increments tigertag counter\n",
    "tigertags_count = 0 # counter for tigertags\n",
    "\n",
    "def increment_tigertags(): \n",
    "    global tigertags_count\n",
    "    tigertags_count += 1\n",
    "\n",
    "# Sets to be used for the cleaning and insertion of data\n",
    "\n",
    "CREATED = [ 'version', 'changeset', 'timestamp', 'user', 'uid']\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Function to find and fix bad url's\n",
    "def fix_urls(element):\n",
    "    if element.tag == 'node' or element.tag == 'way':\n",
    "        if len(element.findall('tag')) > 0:\n",
    "                for tag in element.findall('tag'):\n",
    "                    if tag.attrib['k'] == 'website':\n",
    "                        url = tag.attrib['v']                        \n",
    "                        url = url.lower().strip()\n",
    "                        if not url.startswith('http'):\n",
    "                            print 'old url', url\n",
    "                            url = 'http://' + url\n",
    "                            print 'fixed url', url\n",
    "                        tag.attrib['v'] = url\n",
    "    return element\n",
    "\n",
    "# Function to remove tiger: tags\n",
    "def remove_tigertags(element):\n",
    "    if element.tag == 'way':\n",
    "        tt = False\n",
    "        if len(element.findall('tag')) > 0:\n",
    "                for tag in element.findall('tag'):\n",
    "                    if tag.attrib['k'].startswith('tiger'):\n",
    "                        element.remove(tag)\n",
    "                        increment_tigertags()\n",
    "    return element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function cleans up an element and returns a dictionary document ready to be inserted into a Json file.\n",
    "I use the following structure for my JSON data:\n",
    "\n",
    "    {'address': {'city': 'Detroit',\n",
    "             'country': 'US',\n",
    "             'housenumber': '500',\n",
    "             'postcode': '48226',\n",
    "             'state': 'MI',\n",
    "             'street': 'Woodward Avenue'},\n",
    "     'amenity': 'bank',\n",
    "     'created': {'changeset': '79123908',\n",
    "             'timestamp': '2020-01-02T17:32:29Z',\n",
    "             'uid': '1836535',\n",
    "             'user': 'GITNE',\n",
    "             'version': '2'},\n",
    "     'id': '5965241106',\n",
    "     'name': 'Flagstar Bank',\n",
    "     'pos': [42.3299882, -83.0451545],\n",
    "     'type': 'node',\n",
    "     'visible': 'true'}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes a Elementtree element and returns cleaned up json ready dictionary\n",
    "#This function is modified from 12: Quiz Preparing for Database MongDB in the Udacity material\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag in ROOTTAGS:\n",
    "        \n",
    "        fix_urls(element) #Fixes bad URL's\n",
    "        remove_tigertags(element)#Removes tiger tags\n",
    "        \n",
    "        node['type'] = element.tag\n",
    "        node['id'] = element.attrib['id']\n",
    "        if 'visible' in element.attrib:\n",
    "            node['visible'] = element.attrib['visible']\n",
    "        node['created'] = {}\n",
    "        \n",
    "        for x in CREATED: #Rolls up created info tags\n",
    "            node['created'][x] = element.attrib[x]\n",
    "            \n",
    "        if 'lat' in element.attrib: #adds Long and Lat tuple to document\n",
    "            node['pos'] = (float(element.attrib['lat']), float(element.attrib['lon']))\n",
    "        \n",
    "        # Rolls up address tags and adds other tags to document\n",
    "        if len(element.findall('tag')) > 0:\n",
    "            node['address'] = {}\n",
    "            for tag in element.findall('tag'):\n",
    "                \n",
    "                if problemchars.search(tag.attrib['k']): #checks for bad characters\n",
    "                    pass\n",
    "                elif tag.attrib['k'] == 'type':\n",
    "                    node['relation_type'] = tag.attrib['v']\n",
    "                elif 'addr:' in tag.attrib['k']:\n",
    "                    if len(tag.attrib['k'].split(':')) > 2:\n",
    "                        pass\n",
    "                    else:\n",
    "                        addc = tag.attrib['k'].split(':')[1]\n",
    "                        node['address'][addc] = tag.attrib['v']\n",
    "                else:\n",
    "                    node[tag.attrib['k']] = tag.attrib['v']\n",
    "                    \n",
    "        #makes list of node_refs tags            \n",
    "        if len(element.findall('nd')) > 0: \n",
    "            node['node_refs'] = []\n",
    "            for nd in element.findall('nd'):\n",
    "                node['node_refs'].append(nd.attrib['ref'])\n",
    "                \n",
    "        # removes empty address tags                \n",
    "        if 'address' in node: \n",
    "                if len(node['address']) == 0:\n",
    "                    del node['address']\n",
    "        \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we iterate through the OSM file, calling the shape_element function,  and output the cleaned data to a Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old url www.eatdimestore.com\n",
      "fixed url http://www.eatdimestore.com\n",
      "old url parcderoit.com\n",
      "fixed url http://parcderoit.com\n",
      "Removed 987 tiger tags\n",
      "Output saved to file: openstreetmapdata.json\n"
     ]
    }
   ],
   "source": [
    "# read data into elementtree objects\n",
    "# calls shape_element fuction\n",
    "# writes out json file\n",
    "\n",
    "data = []\n",
    "with codecs.open(outfile, \"w\") as fo:\n",
    "    for _, element in ET.iterparse(usefile):\n",
    "        piece = shape_element(element)\n",
    "        if piece != None:\n",
    "            data.append(piece)\n",
    "            fo.write(json.dumps(piece) + \"\\n\")\n",
    "    print 'Removed', tigertags_count, 'tiger tags'\n",
    "    print 'Output saved to file:', outfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data with MongoDB\n",
    "\n",
    "This inserts our JSON file data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing database\n",
      "Making new database openstreetmap\n"
     ]
    }
   ],
   "source": [
    "# insert into MongoDB database\n",
    "connection = pymongo.MongoClient('localhost', 27017)\n",
    "if 'openstreetmap' in connection.list_database_names():\n",
    "    db = connection['openstreetmap']\n",
    "    db.main.drop() \n",
    "    print('Deleted existing database')\n",
    "\n",
    "print 'Making new database openstreetmap'\n",
    "db = connection['openstreetmap']\n",
    "\n",
    "with open(outfile) as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "    db.main.insert_many(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a mongoDB database. Lets display some statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dbstats',\n",
      " {u'avgObjSize': 273.03551912568304,\n",
      "  u'collections': 1,\n",
      "  u'dataSize': 2498275.0,\n",
      "  u'db': u'openstreetmap',\n",
      "  u'fsTotalSize': 484272263168.0,\n",
      "  u'fsUsedSize': 134843179008.0,\n",
      "  u'indexSize': 4096.0,\n",
      "  u'indexes': 1,\n",
      "  u'numExtents': 0,\n",
      "  u'objects': 9150,\n",
      "  u'ok': 1.0,\n",
      "  u'storageSize': 4096.0,\n",
      "  u'views': 0})\n",
      "4.0 KB file\n",
      "\n",
      "9150 total documents\n",
      "\n",
      "7577 nodes\n",
      "1362 ways\n",
      "211 relations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\py2\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# explore the db with PyMongo\n",
    "#find size stats of database\n",
    "\n",
    "# database stats\n",
    "stats = 'dbstats', db.command('dbstats')  \n",
    "pp(stats)\n",
    "#size of file in KB\n",
    "print db.command('dbstats')['storageSize'] / 1024, 'KB file'\n",
    "\n",
    "# how many nodes, ways, and relations\n",
    "print\n",
    "print db.main.find().count(), 'total documents\\n'\n",
    "print db.main.count_documents({'type':'node'}), 'nodes'\n",
    "print db.main.count_documents({'type':'way'}), 'ways'\n",
    "print db.main.count_documents({'type':'relation'}), 'relations\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out how many unique users contributed to the OSM data. Who are the top 5 contributers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 unique users\n",
      "\n",
      "Top 5 contributers\n",
      "{u'count': 3036, u'_id': u'StudentinGear'}\n",
      "{u'count': 1078, u'_id': u'lmum'}\n",
      "{u'count': 1015, u'_id': u'MichaelGSmith'}\n",
      "{u'count': 542, u'_id': u'marianp_telenav'}\n",
      "{u'count': 480, u'_id': u'jmcbroom'}\n"
     ]
    }
   ],
   "source": [
    "#how many unique users\n",
    "print len(db.main.distinct('created.user')), 'unique users\\n'\n",
    "\n",
    "\n",
    "#Which 5 users contributed the most to the data?\n",
    "result = db.main.aggregate([{'$group' : { '_id' : '$created.user',\n",
    "                                       'count' : {'$sum': 1}}},\n",
    "                            {'$sort' : {'count' : -1 }},\n",
    "                            {'$limit' : 5}])\n",
    "print 'Top 5 contributers'\n",
    "for doc in result:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many bus stops are in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 bus stops\n"
     ]
    }
   ],
   "source": [
    "# number of busstops\n",
    "\n",
    "print db.main.count_documents({'highway':'bus_stop'}), 'bus stops'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Node is the most referenced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the most referenced node:\n",
      "\n",
      "{u'_id': ObjectId('5fa898750e1a32c0ed82ab90'),\n",
      " u'created': {u'changeset': u'65652458',\n",
      "              u'timestamp': u'2018-12-20T21:09:21Z',\n",
      "              u'uid': u'6656962',\n",
      "              u'user': u'StudentinGear',\n",
      "              u'version': u'2'},\n",
      " u'id': u'1236512572',\n",
      " u'pos': [42.3320589, -83.0430423],\n",
      " u'type': u'node',\n",
      " u'visible': u'true'}\n",
      "Referenced in 7 records\n"
     ]
    }
   ],
   "source": [
    "# which node is referenced the most?\n",
    "    \n",
    "result = db.main.aggregate([ {'$match' : {'type' : {'$in': ['way', 'relation']}}},\n",
    "                           {'$unwind': '$node_refs'},\n",
    "                           {'$group': {'_id' : '$node_refs',\n",
    "                                      'count' :{'$sum': 1}}},\n",
    "                           {'$sort' : { 'count' : -1 }},\n",
    "                           {'$limit' : 1 }])\n",
    "print 'Here is the most referenced node:\\n'\n",
    "for doc in result:    \n",
    "    id = doc['_id']\n",
    "    for i in db.main.find({'id' : id}):\n",
    "        pp(i)\n",
    "        print 'Referenced in', doc['count'], 'records'\n",
    "        coords = i['pos']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the cool features of mongodb is Geospacial queries. I'm going  to try one.\n",
    "What are the 5 closest restaurants to that node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Five nearest restaurants \n",
      "\n",
      "Cadillac Square Diner\n",
      "111 Cadillac Square\n",
      "Cuisine american\n",
      "----------------\n",
      "IHOP\n",
      "No address given\n",
      "Cuisine breakfast;pancake\n",
      "----------------\n",
      "Lunch Time Global\n",
      "660 Woodward Avenue\n",
      "Cuisine soup\n",
      "----------------\n",
      "Applebee's\n",
      "No address given\n",
      "Cuisine american\n",
      "----------------\n",
      "Central Kitchen + Bar\n",
      "660 Woodward Avenue\n",
      "Cuisine american\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# 5 closest retaurants to that node\n",
    "\n",
    "#build index on id, geo2d index on pos field\n",
    "db.main.create_index([('pos', pymongo.GEO2D)])\n",
    "\n",
    "closest_restaurants = db.main.find({'pos' : {'$near':  coords}, 'amenity' : 'restaurant'}).limit(5)\n",
    "print '\\nFive nearest restaurants \\n'\n",
    "for i in closest_restaurants:    \n",
    "    print i['name']\n",
    "    if 'address' in i:\n",
    "        print i['address']['housenumber'], i['address']['street']\n",
    "    else:\n",
    "        print 'No address given'\n",
    "    if 'cuisine' in i:\n",
    "        print 'Cuisine', i['cuisine']\n",
    "    print '----------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas about the dataset\n",
    "\n",
    "Openstreetmap is a great resource if you want a bare bones mapping system available without a cost. The popular Pokemon Go app, for instance, runs on Openstreetmap data. There is a lot of incomplete data about amenities such as restaurants and stores. Entries lack addresses, phone numbers, and websites. I also noticed that most nodes have no description at all. All of this is fixable under their current system with better quality contributions.\n",
    "\n",
    "Here is a sample of restaurants and stores missing address data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants\n",
      "{u'_id': ObjectId('5fa898750e1a32c0ed82ae3d'),\n",
      " u'amenity': u'restaurant',\n",
      " u'created': {u'changeset': u'29172136',\n",
      "              u'timestamp': u'2015-03-01T08:55:28Z',\n",
      "              u'uid': u'2441939',\n",
      "              u'user': u'thevirginian',\n",
      "              u'version': u'3'},\n",
      " u'cuisine': u'thai',\n",
      " u'id': u'2390730308',\n",
      " u'name': u'Bangkok Crossing',\n",
      " u'pos': [42.3306851, -83.0456979],\n",
      " u'type': u'node',\n",
      " u'visible': u'true',\n",
      " u'website': u'http://www.bangkokcrossingthaifood.com/'}\n",
      "\n",
      "{u'_id': ObjectId('5fa898750e1a32c0ed82ae4d'),\n",
      " u'amenity': u'restaurant',\n",
      " u'created': {u'changeset': u'45788919',\n",
      "              u'timestamp': u'2017-02-03T20:06:34Z',\n",
      "              u'uid': u'1482360',\n",
      "              u'user': u'jmcbroom',\n",
      "              u'version': u'2'},\n",
      " u'cuisine': u'tex-mex',\n",
      " u'id': u'2558966844',\n",
      " u'name': u'Calexico',\n",
      " u'pos': [42.3329263, -83.0474543],\n",
      " u'type': u'node',\n",
      " u'visible': u'true'}\n",
      "\n",
      "{u'_id': ObjectId('5fa898750e1a32c0ed82b3b9'),\n",
      " u'amenity': u'restaurant',\n",
      " u'created': {u'changeset': u'45791955',\n",
      "              u'timestamp': u'2017-02-03T22:03:46Z',\n",
      "              u'uid': u'1482360',\n",
      "              u'user': u'jmcbroom',\n",
      "              u'version': u'1'},\n",
      " u'cuisine': u'steak_house',\n",
      " u'id': u'4661181827',\n",
      " u'name': u'Texas De Brazil',\n",
      " u'pos': [42.3324368, -83.0471077],\n",
      " u'type': u'node',\n",
      " u'visible': u'true'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# give us 3 restaurants that are missing address data\n",
    "sample_restaurants = db.main.find({'type' : 'node', 'amenity':'restaurant', 'address': {'$exists' : False}}).limit(3)\n",
    "\n",
    "print 'Restaurants'\n",
    "for doc in sample_restaurants:\n",
    "    pp(doc)\n",
    "    print\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shops\n",
      "{u'_id': ObjectId('5fa898750e1a32c0ed82b9c3'),\n",
      " u'created': {u'changeset': u'63243814',\n",
      "              u'timestamp': u'2018-10-05T21:25:32Z',\n",
      "              u'uid': u'1723055',\n",
      "              u'user': u'Johnny Mapperseed',\n",
      "              u'version': u'1'},\n",
      " u'id': u'5959960423',\n",
      " u'name': u'Pure Detroit',\n",
      " u'pos': [42.3266229, -83.048085],\n",
      " u'shop': u'clothes',\n",
      " u'type': u'node',\n",
      " u'visible': u'true'}\n",
      "\n",
      "{u'_id': ObjectId('5fa898750e1a32c0ed82b9cc'),\n",
      " u'brand': u'Under Armour',\n",
      " u'brand:wikidata': u'Q2031485',\n",
      " u'brand:wikipedia': u'en:Under Armour',\n",
      " u'clothes': u'men;women',\n",
      " u'created': {u'changeset': u'72497367',\n",
      "              u'timestamp': u'2019-07-22T03:59:06Z',\n",
      "              u'uid': u'115918',\n",
      "              u'user': u'Timothy Smith',\n",
      "              u'version': u'2'},\n",
      " u'id': u'5960160426',\n",
      " u'name': u'Under Armour',\n",
      " u'pos': [42.3329852, -83.0481265],\n",
      " u'shop': u'clothes',\n",
      " u'type': u'node',\n",
      " u'visible': u'true'}\n",
      "\n",
      "{u'_id': ObjectId('5fa898750e1a32c0ed82b9f7'),\n",
      " u'created': {u'changeset': u'63293170',\n",
      "              u'timestamp': u'2018-10-08T01:43:00Z',\n",
      "              u'uid': u'1723055',\n",
      "              u'user': u'Johnny Mapperseed',\n",
      "              u'version': u'1'},\n",
      " u'id': u'5965241107',\n",
      " u'name': u'BESA',\n",
      " u'pos': [42.3304601, -83.0455006],\n",
      " u'shop': u'yes',\n",
      " u'type': u'node',\n",
      " u'visible': u'true'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# give us 3 shops that are missing address data\n",
    "sample_stores = db.main.find({'shop' : {'$exists' : True}, 'address' : {'$exists' : False}}).limit(3)\n",
    "\n",
    "print 'Shops'\n",
    "for doc in sample_stores:\n",
    "    pp(doc)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the map data in OSM is contributed by volunteers. As is, I would have to cross reference some address database to find a restaurant near me. They could contact businesses and encourage them to make their own entries and keep them up to date. Maybe the local chambr of commerce could be involved.  They could also find corporate sponsors that have a stake in having up to date map data, like auto manufacturers or ride share companies, to pay to have their employees contribute to the map data. Opensteetmap has a lot of potential because it is opensource and anybody can contribute. In the future, I would like to see elevation tags added to the node data so that it can be use for topographical mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### websites I used for reference\n",
    "\n",
    "    https://wiki.openstreetmap.org/wiki/Elements\n",
    "    https://www.tutorialspoint.com/how-to-count-the-number-of-documents-in-a-mongodb-collection\n",
    "    https://docs.mongodb.com/manual/reference/command/dbStats/#dbStats.dataSize\n",
    "    https://docs.mongodb.com/manual/core/2dsphere/\n",
    "    https://docs.mongodb.com/manual/reference/operator/aggregation/\n",
    "    https://www.geeksforgeeks.org/drop-collection-if-already-exists-in-mongodb-using-python/\n",
    "    https://docs.python.org/2/library/xml.etree.elementtree.html\n",
    "    https://docs.python.org/3/library/json.html\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
